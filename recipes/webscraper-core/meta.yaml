package:
  name: webscraper-core
  version: "0.1.1"

source:
  fn: webscraper-core-0.1.1.tar.gz
  url: https://pypi.python.org/packages/source/w/webscraper-core/webscraper-core-0.1.1.tar.gz
  md5: deb3faba90520cc967a4fc26d2b7bf2a
#  patches:
   # List any patch files here
   # - fix.patch

# build:
  # preserve_egg_dir: True
  # entry_points:
    # Put any entry points (scripts to be generated automatically) here. The
    # syntax is module:function.  For example
    #
    # - webscraper-core = webscraper-core:main
    #
    # Would create an entry point called webscraper-core that calls webscraper-core.main()


  # If this is a new build for the same version, increment the build
  # number. If you do not include this key, it defaults to 0.
  # number: 1

requirements:
  build:
    - python
    - setuptools
    - nose ==1.1.2
    - coverage ==3.5.1
    - simplejson
    - pybreaker ==0.2.2
    - pymongo ==2.7.1
    - requests ==2.3.0

  run:
    - python
    - nose ==1.1.2
    - coverage ==3.5.1
    - simplejson
    - pybreaker ==0.2.2
    - pymongo ==2.7.1
    - requests ==2.3.0

test:
  # Python imports
  imports:
    - scraper
    - scraper.models
    - scraper.repository
    - scraper.repository.mongodb

  # commands:
    # You can put test commands to be run here.  Use this to test that the
    # entry points work.


  # You can also put a file called run_test.py in the recipe that will be run
  # at test time.

  # requires:
    # Put any additional test requirements here.  For example
    # - nose

about:
  home: https://github.com/victorpantoja/scraper
  license: MIT
  summary: u'Just an easy way to get Facebook and Twitter Profiles'

# See
# http://docs.continuum.io/conda/build.html for
# more information about meta.yaml
