package:
  name: cesarvaliente_mswl_webcrawler
  version: "1.0"

source:
  fn: CesarValiente_MSWL_WebCrawler-1.0.tar.gz
  url: https://pypi.python.org/packages/source/C/CesarValiente_MSWL_WebCrawler/CesarValiente_MSWL_WebCrawler-1.0.tar.gz
  md5: 28c7abc3c5b62c72588d83eaf2f27b77
#  patches:
   # List any patch files here
   # - fix.patch

# build:
  # preserve_egg_dir: True
  # entry_points:
    # Put any entry points (scripts to be generated automatically) here. The
    # syntax is module:function.  For example
    #
    # - cesarvaliente_mswl_webcrawler = cesarvaliente_mswl_webcrawler:main
    #
    # Would create an entry point called cesarvaliente_mswl_webcrawler that calls cesarvaliente_mswl_webcrawler.main()


  # If this is a new build for the same version, increment the build
  # number. If you do not include this key, it defaults to 0.
  # number: 1

requirements:
  build:
    - python
    - setuptools
    - beautifulsoup

  run:
    - python
    - beautifulsoup

test:
  # Python imports
  imports:
    - cesarvaliente_mswl_webcrawler
    - pymycraaawler

  # commands:
    # You can put test commands to be run here.  Use this to test that the
    # entry points work.


  # You can also put a file called run_test.py in the recipe that will be run
  # at test time.

  # requires:
    # Put any additional test requirements here.  For example
    # - nose

about:
  home: https://github.com/CesarValiente/FLOSS
  license: GNU GPLv3
  summary: 'WebCrawler for the  Development & Tools subject of the M.Sc. on Free Software'

# See
# http://docs.continuum.io/conda/build.html for
# more information about meta.yaml
